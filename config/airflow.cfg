[core]
dags_folder = /opt/airflow/dags
hostname_callable = airflow.utils.net.getfqdn
might_contain_dag_callable = airflow.utils.file.might_contain_dag_via_default_heuristic
default_timezone = Asia/Kuala_Lumpur
executor = CeleryExecutor
auth_manager = airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
parallelism = 8
max_active_tasks_per_dag = 4
dags_are_paused_at_creation = False
max_active_runs_per_dag = 4
max_consecutive_failed_dag_runs_per_dag = 0
load_examples = False
plugins_folder = /opt/airflow/plugins
execute_tasks_new_python_interpreter = False
fernet_key =
donot_pickle = True
dagbag_import_timeout = 10.0
dagbag_import_error_tracebacks = True
dagbag_import_error_traceback_depth = 3
default_impersonation = 
security = 
unit_test_mode = False
allowed_deserialization_classes = airflow.*
allowed_deserialization_classes_regexp = 
killed_task_cleanup_time = 30
dag_run_conf_overrides_params = True
dag_discovery_safe_mode = False
dag_ignore_file_syntax = glob
default_task_retries = 1
default_task_retry_delay = 60
max_task_retry_delay = 300
default_task_weight_rule = downstream
task_success_overtime = 5
default_task_execution_timeout = 300
min_serialized_dag_update_interval = 5
compress_serialized_dags = False
min_serialized_dag_fetch_interval = 5
max_num_rendered_ti_fields_per_task = 30
xcom_backend = airflow.sdk.execution_time.xcom.BaseXCom
lazy_load_plugins = True
lazy_discover_providers = True
hide_sensitive_var_conn_fields = True
sensitive_var_conn_names = 
default_pool_task_slot_count = 32
max_map_length = 256
daemon_umask = 0o077
database_access_isolation = False
internal_api_secret_key = zS+IYHKAu+GmHVW2VHXv2g==
test_connection = Enabled
max_templated_field_length = 4096

[database]
alembic_ini_file_path = alembic.ini
sql_alchemy_conn = postgresql+psycopg2://airflow:airflow@postgres/airflow
sql_engine_encoding = utf-8
sql_alchemy_pool_enabled = True
sql_alchemy_pool_size = 2
sql_alchemy_max_overflow = 5
sql_alchemy_pool_recycle = 900
sql_alchemy_pool_pre_ping = True
sql_alchemy_schema = 
max_db_retries = 3
check_migrations = True
migration_batch_size = 1000

[logging]
base_log_folder = /opt/airflow/logs
remote_logging = False
remote_log_conn_id = 
delete_local_logs = True
google_key_path = 
remote_base_log_folder = 
remote_task_handler_kwargs = 
encrypt_s3_logs = False
logging_level = INFO
celery_logging_level = INFO
fab_logging_level = INFO
logging_config_class = 
colored_console_log = True
colored_log_format = [%%(blue)s%%(asctime)s%%(reset)s] {%%(blue)s%%(filename)s:%%(reset)s%%(lineno)d} %%(log_color)s%%(levelname)s%%(reset)s - %%(log_color)s%%(message)s%%(reset)s
colored_formatter_class = airflow.utils.log.colored_log.CustomTTYColoredFormatter
log_format = [%%(asctime)s] {%%(filename)s:%%(lineno)d} %%(levelname)s - %%(message)s
simple_log_format = %%(asctime)s %%(levelname)s - %%(message)s
dag_processor_log_target = file
dag_processor_log_format = [%%(asctime)s] [SOURCE:DAG_PROCESSOR] {%%(filename)s:%%(lineno)d} %%(levelname)s - %%(message)s
dag_processor_child_process_log_directory = /opt/airflow/logs/dag_processor
log_formatter_class = airflow.utils.log.timezone_aware.TimezoneAware
secret_mask_adapter = 
min_length_masked_secret = 5
task_log_prefix_template = 
log_filename_template = dag_id={{ ti.dag_id }}/run_id={{ ti.run_id }}/task_id={{ ti.task_id }}/{%% if ti.map_index >= 0 %%}map_index={{ ti.map_index }}/{%% endif %%}attempt={{ try_number|default(ti.try_number) }}.log
task_log_reader = task
extra_logger_names = 
worker_log_server_port = 8793
trigger_log_server_port = 8794
file_task_handler_new_folder_permissions = 0o775
file_task_handler_new_file_permissions = 0o664
celery_stdout_stderr_separation = False
color_log_error_keywords = error,exception,failed,traceback
color_log_warning_keywords = warn,warning,deprecated

[metrics]
metrics_allow_list = 
metrics_block_list = 
statsd_on = False
statsd_host = localhost
statsd_ipv6 = False
statsd_port = 8125
statsd_prefix = airflow
stat_name_handler = 
statsd_datadog_enabled = False
statsd_datadog_tags = 
statsd_datadog_metrics_tags = True
statsd_disabled_tags = job_id,run_id
statsd_influxdb_enabled = False
otel_on = False
otel_host = localhost
otel_port = 8889
otel_prefix = airflow
otel_interval_milliseconds = 60000
otel_debugging_on = False
otel_service = Airflow
otel_ssl_active = False

[traces]
otel_on = False
otel_host = localhost
otel_port = 8889
otel_service = Airflow
otel_debugging_on = False
otel_ssl_active = False

[secrets]
backend = 
backend_kwargs = 
use_cache = True
cache_ttl_seconds = 300

[api]
access_denied_message = Access is Denied
secret_key = 4GUERM0FgpRUUGgxKH9q/w==
expose_hostname = True
navbar_color = #fff
navbar_text_color = #51504f
navbar_hover_color = #eee
navbar_text_hover_color = #51504f
enable_swagger_ui = True
expose_config = True
host = 0.0.0.0
port = 8080
workers = 2
worker_timeout = 60
access_logfile = -
ssl_cert = 
ssl_key = 
maximum_page_limit = 100
fallback_page_limit = 50
access_control_allow_headers = 
access_control_allow_methods = 
access_control_allow_origins = 
enable_xcom_deserialize_support = True

[workers]
secrets_backend = 
secrets_backend_kwargs = 
min_heartbeat_interval = 10
max_failed_heartbeats = 5
execution_api_retries = 3
execution_api_retry_wait_min = 1.0
execution_api_retry_wait_max = 30.0

[api_auth]
jwt_expiration_time = 3600
jwt_cli_expiration_time = 1800
jwt_secret = /BVUTpV2LrXz1ZBOunNR2Q==
jwt_leeway = 10

[execution_api]
jwt_expiration_time = 600
jwt_audience = urn:airflow.apache.org:task

[lineage]
backend = 

[operators]
default_owner = airflow
default_deferrable = false
default_cpus = 1
default_ram = 512
default_disk = 512
default_gpus = 0
default_queue = default

[webserver]
grid_view_sorting_order = topological
log_fetch_timeout_sec = 10
hide_paused_dags_by_default = False
page_size = 25
default_wrap = False
x_frame_enabled = True
instance_name_has_markup = False
auto_refresh_interval = 10
warn_deployment_exposure = False
require_confirmation_dag_change = False

[email]
email_backend = airflow.utils.email.send_email_smtp
email_conn_id = smtp_default
default_email_on_retry = False
default_email_on_failure = False
ssl_context = default

[smtp]
smtp_host = localhost
smtp_starttls = True
smtp_ssl = False
smtp_port = 25
smtp_mail_from = airflow@example.com
smtp_timeout = 30
smtp_retry_limit = 3

[sentry]
sentry_on = false
sentry_dsn = 

[scheduler]
job_heartbeat_sec = 10
scheduler_heartbeat_sec = 10
task_instance_heartbeat_sec = 0
num_runs = -1
scheduler_idle_sleep_time = 0.5
parsing_cleanup_interval = 30
pool_metrics_interval = 10.0
running_metrics_interval = 60.0
scheduler_health_check_threshold = 60
enable_health_check = True
scheduler_health_check_server_host = 0.0.0.0
scheduler_health_check_server_port = 8974
orphaned_tasks_check_interval = 60.0
task_instance_heartbeat_timeout = 120
task_instance_heartbeat_timeout_detection_interval = 30.0
catchup_by_default = True
ignore_first_depends_on_past_by_default = True
max_tis_per_query = 8
use_row_level_locking = True
max_dagruns_to_create_per_loop = 5
max_dagruns_per_loop_to_schedule = 10
parsing_pre_import_modules = True
dag_stale_not_seen_duration = 300
use_job_schedule = True
trigger_timeout_check_interval = 30
task_queued_timeout = 300.0
task_queued_timeout_check_interval = 60.0
allowed_run_id_pattern = ^[A-Za-z0-9_.~:+-]+$
create_cron_data_intervals = False
create_delta_data_intervals = False
enable_tracemalloc = True

[triggerer]
capacity = 100
job_heartbeat_sec = 10
triggerer_health_check_threshold = 60

[kerberos]
ccache = /tmp/airflow_krb5_ccache
principal = airflow
reinit_frequency = 3600
kinit_path = kinit
keytab = airflow.keytab
forwardable = True
include_ip = True

[sensors]
default_timeout = 3600

[dag_processor]
dag_bundle_config_list = [      {        "name": "dags-folder",        "classpath": "airflow.dag_processing.bundles.local.LocalDagBundle",        "kwargs": {}      }    ]
refresh_interval = 30
parsing_processes = 1
file_parsing_sort_mode = modified_time
max_callbacks_per_loop = 10
min_file_process_interval = 10
stale_dag_threshold = 25
dag_file_processor_timeout = 30
print_stats_interval = 15
disable_bundle_versioning = True
bundle_refresh_check_interval = 10
stale_bundle_cleanup_interval = 900
stale_bundle_cleanup_age_threshold = 3600
stale_bundle_cleanup_min_versions = 5

[aws]
cloudwatch_task_handler_json_serializer = airflow.providers.amazon.aws.log.cloudwatch_task_handler.json_serialize_legacy

[aws_batch_executor]
conn_id = aws_default
max_submit_job_attempts = 2
check_health_on_startup = True

[aws_ecs_executor]
conn_id = aws_default
assign_public_ip = False
platform_version = LATEST
max_run_task_attempts = 2
check_health_on_startup = True

[aws_auth_manager]
conn_id = aws_default

[celery_kubernetes_executor]
kubernetes_queue = kubernetes

[celery]
celery_app_name = airflow.providers.celery.executors.celery_executor
worker_concurrency = 4
worker_prefetch_multiplier = 1
worker_enable_remote_control = true
broker_url = redis://:@redis:6379/0
result_backend_sqlalchemy_engine_options =
flower_host = 0.0.0.0
flower_url_prefix = 
flower_port = 5555
flower_basic_auth = 
sync_parallelism = 0
celery_config_options = airflow.providers.celery.executors.default_celery.DEFAULT_CELERY_CONFIG
ssl_active = False
ssl_key = 
ssl_cert = 
ssl_cacert = 
pool = prefork
operation_timeout = 2.0
task_acks_late = True
task_track_started = True
task_publish_max_retries = 2
extra_celery_config = {}

[celery_broker_transport_options]

[local_kubernetes_executor]
kubernetes_queue = kubernetes

[kubernetes_executor]
api_client_retry_configuration = 
logs_task_metadata = True
pod_template_file = 
worker_container_repository = 
worker_container_tag = 
namespace = default
delete_worker_pods = True
delete_worker_pods_on_failure = True
worker_pod_pending_fatal_container_state_reasons = CreateContainerConfigError,ErrImagePull,CreateContainerError,ImageInspectError,InvalidImageName
worker_pods_creation_batch_size = 1
multi_namespace_mode = False
multi_namespace_mode_namespace_list = 
in_cluster = True
kube_client_request_args = 
delete_option_kwargs = 
enable_tcp_keepalive = True
tcp_keep_idle = 120
tcp_keep_intvl = 30
tcp_keep_cnt = 6
verify_ssl = True
ssl_ca_cert = 
task_publish_max_retries = 0

[common.io]
xcom_objectstorage_path = 
xcom_objectstorage_threshold = -1
xcom_objectstorage_compression = 

[elasticsearch]
host = 
log_id_template = {dag_id}-{task_id}-{run_id}-{map_index}-{try_number}
end_of_log_mark = end_of_log
frontend = 
write_stdout = True
write_to_es = False
target_index = airflow-logs
json_format = False
json_fields = asctime, filename, lineno, levelname, message
host_field = host
offset_field = offset
index_patterns = _all
index_patterns_callable = 

[elasticsearch_configs]
http_compress = False
verify_certs = True

[fab]
auth_rate_limited = False
auth_rate_limit = 10 per 60 second
update_fab_perms = True
auth_backends = airflow.providers.fab.auth_manager.api.auth.backend.session
config_file = /opt/airflow/webserver_config.py
session_backend = database
session_lifetime_minutes = 1440
fab_admin_user = admin
fab_admin_password = admin
fab_admin_email = admin@example.com
fab_admin_first_name = Admin
fab_admin_last_name = User

[azure_remote_logging]
remote_wasb_log_container = airflow-logs

[openlineage]
disabled = True
disabled_for_operators = 
selective_enable = False
custom_run_facets = 
config_path = 
transport = 
disable_source_code = False
dag_state_change_process_pool_size = 1
execution_timeout = 10
include_full_task_info = False
debug_mode = True
spark_inject_parent_job_info = False
spark_inject_transport_info = False

[standard]
venv_install_method = auto